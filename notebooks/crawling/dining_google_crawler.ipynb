{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e8eec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.WARNING,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('../../log/crawling/crawler.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuration class for crawler settings\"\"\"\n",
    "    CSV_PATH = \"../../data/external/google_gangnam_crawling_data.csv\"\n",
    "    WAIT_TIMEOUT = 3\n",
    "    MAX_SCROLL_ATTEMPTS = 50\n",
    "    MAX_NO_NEW_REVIEWS = 3\n",
    "    MAX_REVIEWS = 100\n",
    "    SLEEP_INTERVAL = 0.3\n",
    "    GOOGLE_MAPS_URL = \"https://www.google.com/maps\"\n",
    "    DININGCODE_URL = \"https://www.diningcode.com/list.dc?query={}\"\n",
    "    \n",
    "class RestaurantCrawler:\n",
    "    def __init__(self, headless: bool = False):\n",
    "        \"\"\"Initialize the crawler with Chrome driver and data storage\"\"\"\n",
    "        self.config = Config()\n",
    "        self.setup_driver(headless)\n",
    "        self.wait = WebDriverWait(self.driver, self.config.WAIT_TIMEOUT)\n",
    "        self.initialize_data()\n",
    "        \n",
    "    def setup_driver(self, headless: bool) -> None:\n",
    "        \"\"\"Setup Chrome WebDriver with options\"\"\"\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--start-maximized\")\n",
    "        if headless:\n",
    "            chrome_options.add_argument(\"--headless\")\n",
    "        try:\n",
    "            self.driver = webdriver.Chrome(\n",
    "                service=Service(ChromeDriverManager().install()),\n",
    "                options=chrome_options\n",
    "            )\n",
    "            logger.info(\"Chrome driver initialized successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize Chrome driver: {e}\")\n",
    "            raise\n",
    "\n",
    "    def initialize_data(self) -> None:\n",
    "        \"\"\"Initialize or load restaurant data from CSV\"\"\"\n",
    "        columns = [\n",
    "            '음식점_이름', '주소', '전화번호', '음식점_태그', '메뉴_정보',\n",
    "            '카테고리', '음식점_사진', '위도', '경도', '영업시간', '리뷰'\n",
    "        ]\n",
    "        if os.path.exists(self.config.CSV_PATH):\n",
    "            self.restaurants_df = pd.read_csv(self.config.CSV_PATH)\n",
    "            logger.info(f\"Loaded existing CSV from {self.config.CSV_PATH}\")\n",
    "        else:\n",
    "            self.restaurants_df = pd.DataFrame(columns=columns)\n",
    "            logger.info(\"Created new empty DataFrame\")\n",
    "\n",
    "    def search_google_maps(self, search_query: str) -> Dict:\n",
    "        \"\"\"Search Google Maps for restaurant information\"\"\"\n",
    "        try:\n",
    "            self.driver.get(self.config.GOOGLE_MAPS_URL)\n",
    "            self._input_search_query(search_query)\n",
    "            \n",
    "            if \"/place/\" not in self.driver.current_url:\n",
    "                self._click_first_result()\n",
    "\n",
    "            return {\n",
    "                '음식점_이름': self._get_restaurant_name(search_query),\n",
    "                '카테고리': self._get_category(),\n",
    "                '음식점_사진': self._get_photo_url(),\n",
    "                '영업시간': self._get_business_hours(),\n",
    "                '위도': self._get_coordinates()[0],\n",
    "                '경도': self._get_coordinates()[1],\n",
    "                '리뷰': self._get_all_reviews()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Google Maps crawling error for {search_query}: {e}\")\n",
    "            return self._get_default_info(search_query)\n",
    "\n",
    "    def _input_search_query(self, query: str) -> None:\n",
    "        \"\"\"Input search query into Google Maps search box\"\"\"\n",
    "        clean_query = re.sub(r'^.*\\(주\\)', '', query)\n",
    "        # 불필요한 공백 제거\n",
    "        clean_query = clean_query.strip()\n",
    "\n",
    "        search_box = self.wait.until(EC.presence_of_element_located((By.ID, \"searchboxinput\")))\n",
    "        search_box.clear()\n",
    "        search_box.send_keys(clean_query)\n",
    "        search_box.send_keys(Keys.ENTER)\n",
    "        time.sleep(1)  # Wait for results to load\n",
    "\n",
    "    def _click_first_result(self) -> None:\n",
    "        \"\"\"Click the first search result\"\"\"\n",
    "        selectors = [\n",
    "            \"a.hfpxzc\", \"div.Nv2PK\", \"div[jsaction*='mouseover']\", \"div.THOPZb\"\n",
    "        ]\n",
    "        for selector in selectors:\n",
    "            try:\n",
    "                results = self.wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, selector)))\n",
    "                if results:\n",
    "                    self.driver.execute_script(\"arguments[0].click();\", results[0])\n",
    "                    time.sleep(1)\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            logger.warning(\"Could not find first result to click\")\n",
    "\n",
    "    def _get_restaurant_name(self, default: str) -> str:\n",
    "        \"\"\"Extract restaurant name\"\"\"\n",
    "        try:\n",
    "            name = self.wait.until(EC.presence_of_element_located(\n",
    "                (By.CSS_SELECTOR, \"h1.DUwDvf.lfPIob\"))).text\n",
    "            return re.sub(r'\\s*\\([^)]*\\)', '', name)\n",
    "        except:\n",
    "            return default\n",
    "\n",
    "    def _get_category(self) -> str:\n",
    "        \"\"\"Extract restaurant category\"\"\"\n",
    "        elements = self.driver.find_elements(By.CSS_SELECTOR, \"button.DkEaL\")\n",
    "        if elements:\n",
    "            return elements[0].text\n",
    "        return \"\"\n",
    "\n",
    "    def _get_photo_url(self) -> str:\n",
    "        \"\"\"Extract restaurant photo URL\"\"\"\n",
    "        selectors = [\"button[aria-label*='사진'] img\", \".RZ66Rb img[decoding='async']\"]\n",
    "        for selector in selectors:\n",
    "            try:\n",
    "                return self.wait.until(EC.presence_of_element_located(\n",
    "                    (By.CSS_SELECTOR, selector))).get_attribute(\"src\")\n",
    "            except:\n",
    "                continue\n",
    "        return \"\"\n",
    "\n",
    "    def _get_business_hours(self) -> Dict:\n",
    "        \"\"\"Extract business hours\"\"\"\n",
    "        try:\n",
    "            hours_button = self.wait.until(EC.element_to_be_clickable(\n",
    "                (By.CSS_SELECTOR, \"div.OMl5r[aria-expanded='false']\")))\n",
    "            hours_button.click()\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "            hours_table = self.wait.until(EC.presence_of_element_located(\n",
    "                (By.CSS_SELECTOR, \"table.eK4R0e\")))\n",
    "            return self._parse_business_hours(hours_table)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to extract business hours: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def _parse_business_hours(self, table) -> Dict:\n",
    "        \"\"\"Parse business hours table into dictionary\"\"\"\n",
    "        hours = {}\n",
    "        for row in table.find_elements(By.CSS_SELECTOR, \"tr.y0skZc\"):\n",
    "            try:\n",
    "                day = row.find_element(By.CSS_SELECTOR, \"td.ylH6lf div\").text\n",
    "                hours_list = [h.text for h in row.find_elements(By.CSS_SELECTOR, \"li.G8aQO\")]\n",
    "                hours[day] = hours_list\n",
    "            except:\n",
    "                continue\n",
    "        return hours\n",
    "\n",
    "    def _get_coordinates(self) -> Tuple[Optional[float], Optional[float]]:\n",
    "        \"\"\"Extract coordinates from URL\"\"\"\n",
    "        try:\n",
    "            url = self.driver.current_url\n",
    "            patterns = [r\"!3d([-\\d\\.]+)!4d([-\\d\\.]+)\", r\"@([-\\d\\.]+),([-\\d\\.]+)\"]\n",
    "            for pattern in patterns:\n",
    "                match = re.search(pattern, url)\n",
    "                if match:\n",
    "                    return float(match.group(1)), float(match.group(2))\n",
    "            return None, None\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to extract coordinates: {e}\")\n",
    "            return None, None\n",
    "\n",
    "    def _get_all_reviews(self) -> List[Dict]:\n",
    "        \"\"\"Collect all reviews\"\"\"\n",
    "        try:\n",
    "            self._navigate_to_reviews_tab()\n",
    "            scroll_container = self._find_scroll_container()\n",
    "            if not scroll_container:\n",
    "                return []\n",
    "\n",
    "            reviews = []\n",
    "            collected_reviews = set()\n",
    "            scroll_attempts = 0\n",
    "            no_new_reviews = 0\n",
    "\n",
    "            while scroll_attempts < self.config.MAX_SCROLL_ATTEMPTS:\n",
    "                review_elements = self.driver.find_elements(By.CSS_SELECTOR, \"div.jftiEf\")\n",
    "                new_reviews_found = False\n",
    "\n",
    "                for review in review_elements:\n",
    "                    review_data = self._process_review(review)\n",
    "                    if review_data and review_data['id'] not in collected_reviews:\n",
    "                        reviews.append(review_data['data'])\n",
    "                        collected_reviews.add(review_data['id'])\n",
    "                        new_reviews_found = True\n",
    "\n",
    "                if not new_reviews_found:\n",
    "                    no_new_reviews += 1\n",
    "                    if no_new_reviews >= self.config.MAX_NO_NEW_REVIEWS:\n",
    "                        break\n",
    "                else:\n",
    "                    no_new_reviews = 0\n",
    "\n",
    "                self._scroll_container(scroll_container)\n",
    "                scroll_attempts += 1\n",
    "                if len(reviews) >= self.config.MAX_REVIEWS:\n",
    "                    break\n",
    "\n",
    "            logger.info(f\"Collected {len(reviews)} reviews\")\n",
    "            return reviews\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Review collection error: {e}\")\n",
    "            return []\n",
    "\n",
    "    def _navigate_to_reviews_tab(self) -> None:\n",
    "        \"\"\"Navigate to reviews tab\"\"\"\n",
    "        try:\n",
    "            review_tab = self.wait.until(EC.element_to_be_clickable(\n",
    "                (By.CSS_SELECTOR, '[role=\"tab\"][aria-label*=\"리뷰\"], [role=\"tab\"][aria-label*=\"Reviews\"]')))\n",
    "            self.driver.execute_script(\"arguments[0].click();\", review_tab)\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to navigate to reviews tab: {e}\")\n",
    "\n",
    "    def _find_scroll_container(self) -> Optional[webdriver.Chrome]:\n",
    "        \"\"\"Find scrollable review container\"\"\"\n",
    "        selectors = [\n",
    "            \"div.m6QErb.DxyBCb.kA9KIf.dS8AEf.XiKgde\",\n",
    "            \"div.m6QErb.XiKgde\",\n",
    "            \"div.m6QErb\",\n",
    "            \"div[role='feed']\"\n",
    "        ]\n",
    "        for selector in selectors:\n",
    "            try:\n",
    "                return self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, selector)))\n",
    "            except:\n",
    "                continue\n",
    "        logger.warning(\"Could not find scroll container\")\n",
    "        return None\n",
    "\n",
    "    def _process_review(self, review) -> Optional[Dict]:\n",
    "        \"\"\"Process individual review\"\"\"\n",
    "        try:\n",
    "            try:\n",
    "                more_button = review.find_element(By.CSS_SELECTOR, \"button.w8nwRe.kyuRq\")\n",
    "                self.driver.execute_script(\"arguments[0].click();\", more_button)\n",
    "                time.sleep(self.config.SLEEP_INTERVAL)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            reviewer = review.find_element(By.CSS_SELECTOR, \"div.d4r55\").text\n",
    "            content = review.find_element(By.CSS_SELECTOR, \"span.wiI7pd\").text\n",
    "            photos = self._get_review_photos(review)\n",
    "            review_id = f\"{reviewer}:{content[:30]}\"\n",
    "\n",
    "            return {\n",
    "                'id': review_id,\n",
    "                'data': {\n",
    "                    'reviewer': reviewer,\n",
    "                    'content': content,\n",
    "                    'photo': photos\n",
    "                }\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error processing review: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _get_review_photos(self, review) -> List[str]:\n",
    "        \"\"\"Extract review photos\"\"\"\n",
    "        try:\n",
    "            photo_container = review.find_element(By.CSS_SELECTOR, \"div.KtCyie\")\n",
    "            photo_buttons = photo_container.find_elements(By.CSS_SELECTOR, \"button.Tya61d\")[:2]\n",
    "            return [\n",
    "                re.search(r'url\\(\"([^\"]+)\"\\)', btn.get_attribute(\"style\")).group(1)\n",
    "                for btn in photo_buttons\n",
    "                if \"background-image: url(\" in btn.get_attribute(\"style\")\n",
    "            ]\n",
    "        except:\n",
    "            return []\n",
    "\n",
    "    def _scroll_container(self, container) -> None:\n",
    "        \"\"\"Scroll container to load more content\"\"\"\n",
    "        try:\n",
    "            self.driver.execute_script(\n",
    "                \"arguments[0].scrollTop = arguments[0].scrollHeight\", container)\n",
    "            time.sleep(self.config.SLEEP_INTERVAL)\n",
    "        except:\n",
    "            actions = ActionChains(self.driver)\n",
    "            actions.move_to_element(container).send_keys(Keys.PAGE_DOWN).perform()\n",
    "            time.sleep(self.config.SLEEP_INTERVAL)\n",
    "\n",
    "    def search_diningcode(self, restaurant_name: str) -> Dict:\n",
    "        \"\"\"Search DiningCode for restaurant information\"\"\"\n",
    "        try:\n",
    "            clean_name = self._clean_restaurant_name(restaurant_name)\n",
    "            self.driver.get(self.config.DININGCODE_URL.format(clean_name))\n",
    "            \n",
    "            first_result = self.wait.until(EC.presence_of_element_located(\n",
    "                (By.CSS_SELECTOR, \"a[id^='block']\")))\n",
    "            self.driver.get(first_result.get_attribute('href'))\n",
    "\n",
    "            return {\n",
    "                '주소': self._get_diningcode_address(),\n",
    "                '전화번호': self._get_diningcode_phone(),\n",
    "                '메뉴_정보': self._get_diningcode_menu(),\n",
    "                '음식점_태그': self._get_diningcode_tags()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"DiningCode crawling error for {restaurant_name}: {e}\")\n",
    "            return {'주소': \"\", '전화번호': \"\", '메뉴_정보': [], '음식점_태그': []}\n",
    "\n",
    "    def _clean_restaurant_name(self, name: str) -> str:\n",
    "        \"\"\"Clean restaurant name for search\"\"\"\n",
    "        return name.rstrip()[:name.rfind(\"점\")] if \"점\" in name else name.rstrip()\n",
    "\n",
    "    def _get_diningcode_address(self) -> str:\n",
    "        \"\"\"Extract address from DiningCode\"\"\"\n",
    "        try:\n",
    "            locat = self.wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'locat')))\n",
    "            address_parts = [a.text for a in locat.find_elements(By.TAG_NAME, 'a')]\n",
    "            address_parts.append(locat.find_element(By.TAG_NAME, 'span').text.strip())\n",
    "            return ' '.join(filter(None, address_parts))\n",
    "        except:\n",
    "            return \"\"\n",
    "\n",
    "    def _get_diningcode_phone(self) -> str:\n",
    "        \"\"\"Extract phone number from DiningCode\"\"\"\n",
    "        try:\n",
    "            return self.wait.until(EC.presence_of_element_located(\n",
    "                (By.CLASS_NAME, 'tel'))).text.strip()\n",
    "        except:\n",
    "            return \"\"\n",
    "\n",
    "    def _get_diningcode_menu(self) -> List[Dict]:\n",
    "        \"\"\"Extract menu information from DiningCode\"\"\"\n",
    "        menu_list = []\n",
    "        try:\n",
    "            menu_section = self.wait.until(EC.presence_of_element_located(\n",
    "                (By.CSS_SELECTOR, \"div.menu-info\")))\n",
    "            self.driver.execute_script(\"arguments[0].scrollIntoView();\", menu_section)\n",
    "            \n",
    "            self._click_more_button(\"a.more-btn\", 1)\n",
    "            \n",
    "            for item in self.driver.find_elements(By.CSS_SELECTOR, \"ul.Restaurant_MenuList li\"):\n",
    "                try:\n",
    "                    name = item.find_element(By.CSS_SELECTOR, \"span.Restaurant_Menu\").text\n",
    "                    price = item.find_element(By.CSS_SELECTOR, \"p.r-txt\").text\n",
    "                    menu_list.append({'menu_name': name, 'menu_price': price})\n",
    "                except:\n",
    "                    continue\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Menu extraction error: {e}\")\n",
    "        return menu_list\n",
    "\n",
    "    def _get_diningcode_tags(self) -> List[Dict]:\n",
    "        \"\"\"Extract tags from DiningCode\"\"\"\n",
    "        tags_list = []\n",
    "        try:\n",
    "            tag_section = self.wait.until(EC.presence_of_element_located(\n",
    "                (By.CSS_SELECTOR, \"ul.app-arti\")))\n",
    "            self.driver.execute_script(\"arguments[0].scrollIntoView();\", tag_section)\n",
    "            \n",
    "            mood_category = tag_section.find_element(\n",
    "                By.XPATH, \"//li[contains(span[@class='btxt'], '분위기')]\")\n",
    "            self._click_more_button(\"span.more-btn.button\", 0, mood_category)\n",
    "            \n",
    "            for tag in mood_category.find_elements(By.CSS_SELECTOR, \"span.icon\"):\n",
    "                if \"more-btn\" not in tag.get_attribute(\"class\"):\n",
    "                    tag_text = tag.text.strip()\n",
    "                    if \"(\" in tag_text and \")\" in tag_text:\n",
    "                        name = tag_text[:tag_text.rfind(\"(\")].strip()\n",
    "                        count = int(tag_text[tag_text.rfind(\"(\")+1:tag_text.rfind(\")\")].strip() or 0)\n",
    "                        tags_list.append({'tags': name, 'count': count})\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Tags extraction error: {e}\")\n",
    "        return tags_list\n",
    "\n",
    "    def _click_more_button(self, selector: str, index: int, parent=None) -> None:\n",
    "        \"\"\"Click more button if available\"\"\"\n",
    "        try:\n",
    "            elements = (parent or self.driver).find_elements(By.CSS_SELECTOR, selector)\n",
    "            if len(elements) > index and elements[index].is_displayed():\n",
    "                self.driver.execute_script(\"arguments[0].click();\", elements[index])\n",
    "                time.sleep(self.config.SLEEP_INTERVAL)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def _get_default_info(self, name: str) -> Dict:\n",
    "        \"\"\"Return default empty information\"\"\"\n",
    "        return {\n",
    "            '음식점_이름': name, '카테고리': '', '음식점_사진': '', '영업시간': {},\n",
    "            '위도': None, '경도': None, '리뷰': [], '주소': '', '전화번호': '',\n",
    "            '메뉴_정보': [], '음식점_태그': []\n",
    "        }\n",
    "\n",
    "    def crawl_restaurant(self, search_query: str) -> Optional[Dict]:\n",
    "        \"\"\"Crawl restaurant information and save to CSV\"\"\"\n",
    "        try:\n",
    "            local = \" 강남구\"\n",
    "            google_info = self.search_google_maps(search_query + local)\n",
    "            dining_info = self.search_diningcode(google_info['음식점_이름'] + local)\n",
    "            restaurant_info = {**dining_info, **google_info}\n",
    "            \n",
    "            self.restaurants_df = pd.concat([\n",
    "                self.restaurants_df,\n",
    "                pd.DataFrame([restaurant_info])\n",
    "            ], ignore_index=True)\n",
    "            \n",
    "            self.save_to_csv()\n",
    "            logger.info(f\"Successfully crawled and saved: {search_query}\")\n",
    "            return restaurant_info\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to crawl {search_query}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def save_to_csv(self, filename: Optional[str] = None) -> None:\n",
    "        \"\"\"Save data to CSV file\"\"\"\n",
    "        save_path = filename or self.config.CSV_PATH\n",
    "        mode = 'a' if os.path.exists(save_path) else 'w'\n",
    "        header = not os.path.exists(save_path)\n",
    "        \n",
    "        self.restaurants_df.iloc[[-1]].to_csv(\n",
    "            save_path, mode=mode, header=header, index=False, encoding='utf-8-sig'\n",
    "        )\n",
    "        logger.info(f\"Data saved to {save_path}\")\n",
    "\n",
    "    def close(self) -> None:\n",
    "        \"\"\"Close the WebDriver\"\"\"\n",
    "        try:\n",
    "            self.driver.quit()\n",
    "            logger.info(\"WebDriver closed successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error closing WebDriver: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    try:\n",
    "        restaurants_df = pd.read_csv('../../data/interim/gangnam_restaurants_cleaned.csv')\n",
    "        crawler = RestaurantCrawler(headless=False)\n",
    "        \n",
    "        for idx, row in restaurants_df.iloc[4150:].iterrows():\n",
    "            name = row['음식점명']\n",
    "            logger.info(f\"Processing restaurant {idx}: {name}\")\n",
    "            \n",
    "            try:\n",
    "                crawler.crawl_restaurant(name)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing {name}: {e}\")\n",
    "                continue\n",
    "                \n",
    "        logger.info(\"Crawling completed successfully\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Main execution error: {e}\")\n",
    "    finally:\n",
    "        crawler.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9b14e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e8eec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'써브웨이' 정보 수집 중...\n",
      "https://www.google.com/maps/search/%EC%8D%A8%EB%B8%8C%EC%9B%A8%EC%9D%B4?entry=ttu&g_ep=EgoyMDI1MDUwMy4wIKXMDSoASAFQAw%3D%3D\n",
      "데이터가 ../../data/external/google_gangnam_crawling_data.csv에 저장되었습니다.\n",
      "크롤링 완료!\n",
      "     음식점_이름     카테고리                                             음식점_사진  \\\n",
      "0      써브웨이      NaN                                                NaN   \n",
      "1      써브웨이      NaN                                                NaN   \n",
      "2  서브웨이 학동점  샌드위치 가게  https://lh3.googleusercontent.com/gps-cs-s/AC9...   \n",
      "3      써브웨이      NaN                                                NaN   \n",
      "4      써브웨이      NaN                                                NaN   \n",
      "5  서브웨이 학동점  샌드위치 가게  https://lh3.googleusercontent.com/gps-cs-s/AC9...   \n",
      "6  서브웨이 학동점  샌드위치 가게  https://lh3.googleusercontent.com/p/AF1QipMuTT...   \n",
      "7  서브웨이 학동점  샌드위치 가게  https://lh3.googleusercontent.com/p/AF1QipMuTT...   \n",
      "\n",
      "                                                영업시간  \\\n",
      "0                                                 {}   \n",
      "1                                                 {}   \n",
      "2  {'수요일': ['24시간 영업'], '목요일': ['24시간 영업'], '금요일'...   \n",
      "3                                                 {}   \n",
      "4                                                 {}   \n",
      "5  {'수요일': ['24시간 영업'], '목요일': ['24시간 영업'], '금요일'...   \n",
      "6  {'수요일': ['24시간 영업'], '목요일': ['24시간 영업'], '금요일'...   \n",
      "7  {'수요일': ['24시간 영업'], '목요일': ['24시간 영업'], '금요일'...   \n",
      "\n",
      "                                                  리뷰   주소 전화번호 음식점_태그  \\\n",
      "0                                                NaN  NaN  NaN    NaN   \n",
      "1                                                NaN  NaN  NaN    NaN   \n",
      "2  최동호_Bryan - 별표 4개\\n학동역 6번 출구 근처의 서브웨이 입니다. 햄버거...  NaN  NaN    NaN   \n",
      "3                                                NaN  NaN  NaN    NaN   \n",
      "4                                                NaN  NaN  NaN    NaN   \n",
      "5  최동호_Bryan - 별표 4개\\n학동역 6번 출구 근처의 서브웨이 입니다. 햄버거...  NaN  NaN    NaN   \n",
      "6  최동호_Bryan - 별표 4개\\n학동역 6번 출구 근처의 서브웨이 입니다. 햄버거...  NaN  NaN    NaN   \n",
      "7  최동호_Bryan - 별표 4개\\n학동역 6번 출구 근처의 서브웨이 입니다. 햄버거...                    \n",
      "\n",
      "                                               메뉴_정보  \n",
      "0  메뉴정보\\n터키 베이컨 에그 슬라이스 추천\\n8,100원\\n터키 베이컨 아보카도 추...  \n",
      "1  메뉴정보\\n터키 베이컨 에그 슬라이스 추천\\n8,100원\\n터키 베이컨 아보카도 추...  \n",
      "2                                                NaN  \n",
      "3  메뉴정보\\n터키 베이컨 에그 슬라이스 추천\\n8,100원\\n터키 베이컨 아보카도 추...  \n",
      "4  메뉴정보\\n터키 베이컨 에그 슬라이스 추천\\n8,100원\\n터키 베이컨 아보카도 추...  \n",
      "5                                                NaN  \n",
      "6                                                NaN  \n",
      "7                                                     \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "class RestaurantCrawler:\n",
    "    def __init__(self):\n",
    "        # 크롬 드라이버 설정\n",
    "        self.chrome_options = Options()\n",
    "        self.chrome_options.add_argument(\"--start-maximized\")\n",
    "        # self.chrome_options.add_argument(\"--headless\")  # 필요시 헤드리스 모드 활성화\n",
    "        self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), \n",
    "                                       options=self.chrome_options)\n",
    "        self.wait = WebDriverWait(self.driver, 3)\n",
    "        \n",
    "        csv_path = \"../../data/external/google_gangnam_crawling_data.csv\"\n",
    "\n",
    "        # 결과 저장용 데이터프레임 - 기존 CSV 파일이 있으면 로드, 없으면 빈 데이터프레임 생성\n",
    "        if os.path.exists(csv_path):\n",
    "            self.restaurants_df = pd.read_csv(csv_path)\n",
    "            self.csv_path = csv_path\n",
    "        else:\n",
    "            self.restaurants_df = pd.DataFrame(columns=[\n",
    "                '음식점_이름','카테고리','음식점_사진','영업시간','전화번호',\n",
    "                '리뷰','주소','음식점_태그','메뉴_정보'\n",
    "\n",
    "            ]) # 빈 데이터프레임 생성\n",
    "            self.csv_path = csv_path\n",
    "    \n",
    "    def search_google_maps(self, search_query):\n",
    "        \"\"\"구글 지도에서 음식점 검색 및 정보 수집\"\"\"\n",
    "        try:\n",
    "            self.driver.get(\"https://www.google.com/maps\")\n",
    "            \n",
    "            # 검색창 찾기 및 검색어 입력\n",
    "            search_box = self.wait.until(EC.presence_of_element_located(\n",
    "                (By.ID, \"searchboxinput\")))\n",
    "            search_box.clear()\n",
    "            search_box.send_keys(search_query)\n",
    "            search_box.send_keys(Keys.ENTER)\n",
    "            \n",
    "            # 검색 결과 대기\n",
    "            time.sleep(2)\n",
    "\n",
    "            # 현재 URL 확인하여 상세 페이지인지 목록 페이지인지 판단\n",
    "            current_url = self.driver.current_url\n",
    "            # 여러 결과 (목록 페이지인 경우) - 첫 번째 결과 클릭\n",
    "            if \"/place/\" not in current_url:\n",
    "                try:\n",
    "                    # 첫 번째 결과 찾기\n",
    "                    first_result = self.driver.find_element(By.CSS_SELECTOR, \"a.hfpxzc\")\n",
    "                    \n",
    "                    # 첫 번째 결과 클릭\n",
    "                    first_result.click()\n",
    "                    time.sleep(2)  # 상세 정보 로딩 대기\n",
    "                except Exception as e:\n",
    "                    print(f\"검색 결과 클릭 중 오류: {e}\")\n",
    "            else:\n",
    "                # 음식점 이름\n",
    "                try:\n",
    "                    restaurant_name = self.driver.find_element(\n",
    "                        By.CSS_SELECTOR, \"h1.DUwDvf\").text\n",
    "                except:\n",
    "                    restaurant_name = search_query\n",
    "                \n",
    "                # 카테고리 정보\n",
    "                try:\n",
    "                    category = self.driver.find_element(\n",
    "                        By.CSS_SELECTOR, \"button.DkEaL \").text\n",
    "                except:\n",
    "                    category = \"\"\n",
    "                \n",
    "                # 음식점 사진 URL\n",
    "                try:\n",
    "                    photo_element = self.driver.find_element(\n",
    "                        By.CSS_SELECTOR, \"button[aria-label*='사진'] img\")\n",
    "                    photo_url = photo_element.get_attribute(\"src\")\n",
    "                except:\n",
    "                    try:\n",
    "                        photo_element = self.driver.find_element(\n",
    "                            By.CSS_SELECTOR, \".RZ66Rb img[decoding='async']\")\n",
    "                        photo_url = photo_element.get_attribute(\"src\")\n",
    "                    except:\n",
    "                        photo_url = \"\"\n",
    "\n",
    "                # 영업시간 추출 (버튼 클릭 방식)\n",
    "                try:\n",
    "                    # 영업시간 버튼 찾기 및 클릭\n",
    "                    hours_button = self.driver.find_element(By.CSS_SELECTOR, \"div.OMl5r[aria-expanded='false']\")\n",
    "                    hours_button.click()\n",
    "                    time.sleep(1)  # 테이블이 로드될 시간 부여\n",
    "                    \n",
    "                    # 영업시간 테이블 찾기\n",
    "                    hours_table = self.driver.find_element(By.CSS_SELECTOR, \"table.eK4R0e\")\n",
    "                    \n",
    "                    # 요일별 영업시간 추출\n",
    "                    business_hours = {}\n",
    "                    rows = hours_table.find_elements(By.CSS_SELECTOR, \"tr.y0skZc\")\n",
    "                    \n",
    "                    for row in rows:\n",
    "                        day = row.find_element(By.CSS_SELECTOR, \"td.ylH6lf div\").text\n",
    "                        hours_list = row.find_elements(By.CSS_SELECTOR, \"li.G8aQO\")\n",
    "                        hours_text = [hour.text for hour in hours_list]\n",
    "                        business_hours[day] = hours_text\n",
    "                    \n",
    "                    # 딕셔너리 형태로 저장\n",
    "                    hours = business_hours\n",
    "                except Exception as e:\n",
    "                    print(f\"영업시간 추출 중 오류 발생: {e}\")\n",
    "                    hours = {}\n",
    "\n",
    "                # 리뷰 (최대 5개)\n",
    "                reviews = []\n",
    "                try:\n",
    "                    # 리뷰 섹션으로 이동\n",
    "                    review_tab = self.driver.find_element(By.CSS_SELECTOR, \"button[aria-label*='리뷰']\")\n",
    "                    review_tab.click()\n",
    "\n",
    "                    time.sleep(1)\n",
    "                    \n",
    "                    # 스크롤 다운 함수 - 리뷰 더 로드\n",
    "                    try:\n",
    "                        # 리뷰 컨테이너 찾기 (여러 선택자 시도)\n",
    "                        try:\n",
    "                            scroll_container = self.driver.find_element(By.CSS_SELECTOR, \"div.m6QErb-qJTHM-tJHJj\")\n",
    "                        except:\n",
    "                            try:\n",
    "                                scroll_container = self.driver.find_element(By.CSS_SELECTOR, \"div[role='feed']\")\n",
    "                            except:\n",
    "                                scroll_container = self.driver.find_element(By.XPATH, \"//div[contains(@class, 'section-scrollbox')]\")\n",
    "                        \n",
    "                        # 스크롤 다운 실행\n",
    "                        for _ in range(3):  # 3번 스크롤 다운\n",
    "                            self.driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', scroll_container)\n",
    "                            time.sleep(1.5)  # 로딩 대기 시간 증가\n",
    "                    except Exception as e:\n",
    "                        print(f\"스크롤 다운 중 오류 발생: {e}\")\n",
    "\n",
    "                    \n",
    "                    # 리뷰 요소들 수집\n",
    "                    review_elements = self.driver.find_elements(\n",
    "                        By.CSS_SELECTOR, \"div.jftiEf\")[:5]\n",
    "                    \n",
    "                    for review in review_elements:\n",
    "                        try:\n",
    "                            # 더보기 버튼이 있으면 클릭\n",
    "                            more_button = review.find_element(By.CSS_SELECTOR, \"button.w8nwRe\")\n",
    "                            more_button.click()\n",
    "                            time.sleep(0.5)\n",
    "                        except:\n",
    "                            pass\n",
    "                        \n",
    "                        reviewer = review.find_element(By.CSS_SELECTOR, \"div.d4r55\").text\n",
    "                        rating = review.find_element(\n",
    "                            By.CSS_SELECTOR, \"span.kvMYJc\").get_attribute(\"aria-label\")\n",
    "                        content = review.find_element(By.CSS_SELECTOR, \"span.wiI7pd\").text\n",
    "                        \n",
    "                        reviews.append(f\"{reviewer} - {rating}\\n{content}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"리뷰 수집 중 오류: {e}\")\n",
    "                \n",
    "                return {\n",
    "                    '음식점_이름': restaurant_name,\n",
    "                    '카테고리': category,\n",
    "                    '음식점_사진': photo_url,\n",
    "                    '영업시간': hours,\n",
    "                    '리뷰': \"\\n\\n\".join(reviews)\n",
    "                }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"구글 지도 크롤링 중 오류 발생: {e}\")\n",
    "            return {\n",
    "                '음식점_이름': search_query,\n",
    "                '카테고리': \"\",\n",
    "                '음식점_사진': \"\",\n",
    "                '영업시간': \"\",\n",
    "                '리뷰': \"\"\n",
    "            }\n",
    "    \n",
    "    def search_diningcode(self, restaurant_name):\n",
    "        \"\"\"다이닝코드에서 음식점 검색 및 정보 수집\"\"\"\n",
    "        try:\n",
    "            search_url = f\"https://www.diningcode.com/list.dc?query={restaurant_name}\"\n",
    "            self.driver.get(search_url)\n",
    "            \n",
    "            # 검색 결과 대기\n",
    "            time.sleep(1)\n",
    "            \n",
    "            # 첫 번째 검색 결과의 링크 가져오기\n",
    "            try:\n",
    "                first_result_link = self.wait.until(EC.presence_of_element_located(\n",
    "                    (By.CSS_SELECTOR, \".Poi__List__Wrap a\")))\n",
    "                href = first_result_link.get_attribute('href')\n",
    "                \n",
    "                # 해당 URL로 직접 이동\n",
    "                self.driver.get(href)\n",
    "                time.sleep(2)\n",
    "            except:\n",
    "                print(\"다이닝코드 검색 결과가 없거나 링크를 찾을 수 없습니다.\")\n",
    "                return {'주소': \"\", '음식점_태그': \"\", '메뉴_정보': \"\"}\n",
    "            \n",
    "            # 주소 정보\n",
    "            try:\n",
    "                address = self.driver.find_element(By.CSS_SELECTOR, \".dc-spot-place\").text\n",
    "            except:\n",
    "                address = \"\"\n",
    "            \n",
    "            # 전화번호 추출\n",
    "            try:\n",
    "                phone = self.driver.find_element(By.CSS_SELECTOR, \".dc-spot-tel\").text\n",
    "            except:\n",
    "                phone = \"\"\n",
    "            # 음식점 태그 정보\n",
    "            try:\n",
    "                tags = self.driver.find_element(By.CSS_SELECTOR, \".keywordStyle\").text\n",
    "            except:\n",
    "                tags = \"\"\n",
    "                \n",
    "            # 메뉴 정보\n",
    "            try:\n",
    "                menu_info = self.driver.find_elements(By.CSS_SELECTOR, \".menu-info\")\n",
    "                menu_text = \"\\n\".join([menu.text for menu in menu_info])\n",
    "            except:\n",
    "                menu_text = \"\"\n",
    "            \n",
    "            return {\n",
    "                '주소': address,\n",
    "                '전화번호': phone,\n",
    "                '음식점_태그': tags,\n",
    "                '메뉴_정보': menu_text\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"다이닝코드 크롤링 중 오류 발생: {e}\")\n",
    "            return {\n",
    "                '주소': \"\",\n",
    "                '전화번호': \"\",\n",
    "                '음식점_태그': \"\",\n",
    "                '메뉴_정보': \"\"\n",
    "            }\n",
    "    \n",
    "    def crawl_restaurant(self, search_query):\n",
    "        \"\"\"구글 지도와 다이닝코드에서 음식점 정보 수집\"\"\"\n",
    "        # 구글 지도에서 정보 수집\n",
    "        google_info = self.search_google_maps(search_query)\n",
    "        \n",
    "        # 다이닝코드에서 정보 수집 (구글에서 얻은 음식점 이름 사용)\n",
    "        dining_info = self.search_diningcode(google_info['음식점_이름'])\n",
    "        \n",
    "        # 정보 합치기\n",
    "        restaurant_info = {**google_info, **dining_info}\n",
    "        \n",
    "        # 데이터프레임에 추가\n",
    "        self.restaurants_df = pd.concat([\n",
    "            self.restaurants_df, \n",
    "            pd.DataFrame([restaurant_info])\n",
    "        ], ignore_index=True)\n",
    "        \n",
    "        return restaurant_info\n",
    "    \n",
    "    def crawl_multiple_restaurants(self, search_queries):\n",
    "        \"\"\"여러 음식점 정보 수집\"\"\"\n",
    "        for query in search_queries:\n",
    "            print(f\"'{query}' 정보 수집 중...\")\n",
    "            self.crawl_restaurant(query)\n",
    "            time.sleep(2)  # 요청 간 딜레이\n",
    "        \n",
    "        return self.restaurants_df\n",
    "    \n",
    "    def save_to_csv(self, filename=None):\n",
    "        \"\"\"수집한 데이터를 CSV 파일로 저장\"\"\"\n",
    "        save_path = filename or self.csv_path\n",
    "        \n",
    "        # 파일이 존재하고 데이터프레임이 비어있지 않은 경우\n",
    "        if os.path.exists(save_path) and not self.restaurants_df.empty:\n",
    "            # 헤더 없이 추가 모드로 저장 (기존 파일에 이어서 저장)\n",
    "            self.restaurants_df.to_csv(save_path, mode='a', header=False, index=False, encoding='utf-8-sig')\n",
    "        else:\n",
    "            # 새 파일 생성 모드로 저장\n",
    "            self.restaurants_df.to_csv(save_path, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        print(f\"데이터가 {save_path}에 저장되었습니다.\")\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"드라이버 종료\"\"\"\n",
    "        self.driver.quit()\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    crawler = RestaurantCrawler()\n",
    "    \n",
    "    # 검색할 음식점 목록\n",
    "    restaurants_to_search = [\n",
    "        \"써브웨이\"\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # 여러 음식점 정보 수집\n",
    "        results = crawler.crawl_multiple_restaurants(restaurants_to_search)\n",
    "        \n",
    "        # CSV 파일로 저장\n",
    "        crawler.save_to_csv()\n",
    "        \n",
    "        print(\"크롤링 완료!\")\n",
    "        print(results)\n",
    "    finally:\n",
    "        # 드라이버 종료\n",
    "        crawler.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
